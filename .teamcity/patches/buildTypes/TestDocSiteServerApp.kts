package patches.buildTypes

import jetbrains.buildServer.configs.kotlin.v2019_2.*
import jetbrains.buildServer.configs.kotlin.v2019_2.buildFeatures.CommitStatusPublisher
import jetbrains.buildServer.configs.kotlin.v2019_2.buildFeatures.commitStatusPublisher
import jetbrains.buildServer.configs.kotlin.v2019_2.buildSteps.ScriptBuildStep
import jetbrains.buildServer.configs.kotlin.v2019_2.buildSteps.dockerCommand
import jetbrains.buildServer.configs.kotlin.v2019_2.buildSteps.dockerCompose
import jetbrains.buildServer.configs.kotlin.v2019_2.buildSteps.script
import jetbrains.buildServer.configs.kotlin.v2019_2.ui.*

/*
This patch script was generated by TeamCity on settings change in UI.
To apply the patch, change the buildType with id = 'TestDocSiteServerApp'
accordingly, and delete the patch script.
*/
changeBuildType(RelativeId("TestDocSiteServerApp")) {
    expectSteps {
        dockerCompose {
            name = "Compose services"
            file = "apps/doc_crawler/tests/test_doc_crawler/resources/docker-compose.yml"
        }
        dockerCommand {
            name = "Build the doc crawler Docker image locally"
            commandType = build {
                source = file {
                    path = "apps/doc_crawler/Dockerfile"
                }
                namesAndTags = "doc-crawler:local"
                commandArgs = "--pull"
            }
            param("dockerImage.platform", "linux")
        }
        script {
            name = "Crawl the document and update the local index"
            scriptContent = """
                #!/bin/bash
                set -xe
                
                export APP_BASE_URL="http://localhost/"
                export INDEX_NAME="gw-docs"
                export ELASTICSEARCH_URLS="http://localhost:9200"
                export DOC_S3_URL="http://localhost/"
                export CONFIG_FILE="%teamcity.build.workingDir%/apps/doc_crawler/tests/test_doc_crawler/resources/input/config/gw-docs.json"
                
                cat > scrapy.cfg <<- EOM
                [settings]
                default = doc_crawler.settings
                EOM
                
                doc_crawler
            """.trimIndent()
            dockerImagePlatform = ScriptBuildStep.ImagePlatform.Linux
            dockerImage = "doc-crawler:local"
        }
        script {
            name = "Test the doc site server"
            scriptContent = """
                #!/bin/bash
                set -e
                export APP_BASE_URL="http://localhost:8081"
                export ELASTICSEARCH_URL="http://localhost:9200"
                
                cd server/
                npm install
                npm test
            """.trimIndent()
            dockerPull = true
            dockerImage = "artifactory.guidewire.com/hub-docker-remote/node:14-alpine"
        }
    }
    steps {
        update<ScriptBuildStep>(3) {
            clearConditions()
            scriptContent = """
                #!/bin/bash
                set -e
                export APP_BASE_URL="http://localhost:8081"
                export ELASTICSEARCH_URL="http://localhost:9200"
                
                echo ${'$'}(pwd)
                cd server/
                npm install
                npm test
            """.trimIndent()
        }
    }

    features {
        val feature1 = find<CommitStatusPublisher> {
            commitStatusPublisher {
                publisher = bitbucketServer {
                    url = "https://stash.guidewire.com"
                    userName = "%env.SERVICE_ACCOUNT_USERNAME%"
                    password = "%env.BITBUCKET_ACCESS_TOKEN%"
                }
            }
        }
        feature1.apply {
            publisher = bitbucketServer {
                url = "https://stash.guidewire.com"
                userName = "%env.SERVICE_ACCOUNT_USERNAME%"
                password = "credentialsJSON:28000373-d3ae-4957-878b-a52ae604781a"
            }
        }
    }
}
